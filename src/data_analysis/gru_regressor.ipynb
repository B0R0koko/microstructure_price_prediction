{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import DataPrepare\n",
    "from gru_training_utils import TimeSeriesDataset, mape\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pl.DataFrame = pl.read_parquet(r'C:\\Users\\310\\Desktop\\Progects_Py\\data\\microstructure_price_prediction_data\\dfs\\2024-06-29 20-00-00_2024-07-01 00-00-00_delta_0-00-10_return_5_sec.parquet')\n",
    "target_var: str = \"log_return\"\n",
    "cat_features = ['currency_pair']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataPrepare(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test ratio is 0.8\n",
      "Train len for DOGEUSDT is 7616\n",
      "Test len for DOGEUSDT is 1904\n",
      "Train len for AVAXUSDT is 6586\n",
      "Test len for AVAXUSDT is 1647\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TimeSeriesDataset(df=df_train, target_var=target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_features: int, num_currency_pairs: int,\n",
    "                 hidden_size: int, num_layers: int, dropout: float):\n",
    "        \"\"\"\n",
    "        input_features: number of features per currency pair\n",
    "        num_currency_pairs: how many currency pairs we have\n",
    "        hidden_size: number of units in GRU hidden layer(s)\n",
    "        num_layers: number of stacked GRU layers\n",
    "        dropout: dropout rate between GRU layers (if num_layers > 1)\n",
    "        \"\"\"\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.num_currency_pairs = num_currency_pairs\n",
    "        self.input_features = input_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Input size to GRU = input_features * num_currency_pairs\n",
    "        input_size = input_features * num_currency_pairs\n",
    "\n",
    "        # Define GRU\n",
    "        # batch_first=True means input is (batch, seq_len, input_size)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Final fully connected layer to map hidden state to num_currency_pairs predictions\n",
    "        self.fc = nn.Linear(hidden_size, num_currency_pairs)\n",
    "\n",
    "    def forward(self, X, h=None):\n",
    "        # X shape: (batch, seq_length, features, currency_pairs)\n",
    "        B, F, C, L = X.shape\n",
    "        #[32, 11, 2, 10]\n",
    "        # From (B, F, C, L) to (B, L, F, C)\n",
    "        X = X.permute(0, 3, 1, 2)  # 0->0, 3->1, 1->2, 2->3\n",
    "        # Now X is (32, 10, 11, 2), which means:\n",
    "        # B=32, L=10, F=11, C=2\n",
    "        \n",
    "        X = X.reshape(B, L, F*C)   # (32, 10, 22)\n",
    "        # Pass through GRU\n",
    "        # out: (B, L, hidden_size)\n",
    "        # If h is provided, use it as initial hidden state\n",
    "        out, h_n = self.gru(X, h)  # out: (B, L, hidden_size)\n",
    "        last_out = out[:, -1, :]   # (B, hidden_size)\n",
    "        preds = self.fc(last_out)  # (B, num_currency_pairs)\n",
    "        return preds, h_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    input_features,\n",
    "    num_currency_pairs,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.2,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    "    log_dir=\"./logs\"\n",
    "):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    model = GRUModel(input_features, num_currency_pairs, hidden_size, num_layers, dropout)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    global_step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        h = None\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds, h = model(X_batch, h)\n",
    "            h = h.detach()\n",
    "\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            writer.add_scalar(\"Train/MSE\", loss.item(), global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        avg_train_mse = train_loss / len(train_loader)\n",
    "        avg_train_rmse = math.sqrt(avg_train_mse)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                preds, _ = model(X_batch, None)\n",
    "                loss = criterion(preds, y_batch)\n",
    "                val_loss += loss.item()\n",
    "                all_preds.append(preds)\n",
    "                all_targets.append(y_batch)\n",
    "                val_steps += 1\n",
    "\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_targets = torch.cat(all_targets, dim=0)\n",
    "        avg_val_mse = val_loss / val_steps\n",
    "        avg_val_rmse = math.sqrt(avg_val_mse)\n",
    "        current_mape = mape(all_preds, all_targets)\n",
    "\n",
    "        writer.add_scalar(\"Val/RMSE\", avg_val_rmse, epoch)\n",
    "        writer.add_scalar(\"Val/MAPE\", current_mape, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train RMSE: {avg_train_rmse:.6f}, \"\n",
    "              f\"Val RMSE: {avg_val_rmse:.6f}, \"\n",
    "              f\"Val MAPE: {current_mape:.2f}%\")\n",
    "\n",
    "        # Every 5 epochs: plot predictions vs. true values\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            # Let's take the first batch from test_loader again to plot\n",
    "            X_plot, y_plot = next(iter(test_loader))\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                p_plot, _ = model(X_plot, None)\n",
    "\n",
    "            # Convert to numpy\n",
    "            p_np = p_plot.cpu().numpy()\n",
    "            t_np = y_plot.cpu().numpy()\n",
    "\n",
    "            # We'll plot the predictions for the first currency pair only\n",
    "            currency_pair_idx = 0\n",
    "            fig, ax = plt.subplots(figsize=(8, 4))\n",
    "            ax.plot(t_np[:, currency_pair_idx], label='True', marker='o')\n",
    "            ax.plot(p_np[:, currency_pair_idx], label='Pred', marker='x')\n",
    "            ax.set_title(f'Epoch {epoch+1} Predictions vs True (CP index {currency_pair_idx})')\n",
    "            ax.set_xlabel('Sample index in batch')\n",
    "            ax.set_ylabel('Value')\n",
    "            ax.legend()\n",
    "\n",
    "            # Log the figure to TensorBoard\n",
    "            writer.add_figure(\"Val/Predictions\", fig, epoch)\n",
    "            plt.close(fig)\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train RMSE: 0.014236, Val RMSE: 0.001804, Val MAPE: 79054.09%\n",
      "Epoch 2/10, Train RMSE: 0.002213, Val RMSE: 0.001221, Val MAPE: 69814.61%\n",
      "Epoch 3/10, Train RMSE: 0.001718, Val RMSE: 0.001356, Val MAPE: 69432.66%\n",
      "Epoch 4/10, Train RMSE: 0.001240, Val RMSE: 0.000955, Val MAPE: 40507.09%\n",
      "Epoch 5/10, Train RMSE: 0.000921, Val RMSE: 0.001322, Val MAPE: 60986.18%\n",
      "Epoch 6/10, Train RMSE: 0.000948, Val RMSE: 0.001769, Val MAPE: 98906.95%\n",
      "Epoch 7/10, Train RMSE: 0.001115, Val RMSE: 0.002026, Val MAPE: 118303.76%\n",
      "Epoch 8/10, Train RMSE: 0.000795, Val RMSE: 0.000315, Val MAPE: 9614.21%\n",
      "Epoch 9/10, Train RMSE: 0.000494, Val RMSE: 0.000411, Val MAPE: 19068.13%\n",
      "Epoch 10/10, Train RMSE: 0.001810, Val RMSE: 0.000532, Val MAPE: 27054.94%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = TimeSeriesDataset(df=df_train, target_var=\"log_return\", cat_features=['currency_pair'], seq_length=10)\n",
    "test_dataset = TimeSeriesDataset(df=df_test, target_var=\"log_return\", cat_features=['currency_pair'], seq_length=10)\n",
    "\n",
    "input_features = train_dataset.num_features\n",
    "num_currency_pairs = train_dataset.num_currency_pairs\n",
    "\n",
    "train_model(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    input_features,\n",
    "    num_currency_pairs,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    dropout=0.2,\n",
    "    learning_rate=1e-3,\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    "    log_dir=\"./logs\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microstructure-price-prediction-p_py7spM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
