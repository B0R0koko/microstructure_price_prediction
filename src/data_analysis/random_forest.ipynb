{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing_utils import train_test_split, target_encoding, X_y_split, DataPrepare\n",
    "\n",
    "import json\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from optuna.storages import RDBStorage\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from dash import Dash, html, dcc\n",
    "import plotly.express as px\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pl.DataFrame = pl.read_parquet(r'C:\\Users\\310\\Desktop\\Progects_Py\\data\\microstructure_price_prediction_data\\cross_section\\df_cross_section_V0.1_.parquet')\n",
    "target_var: str = \"target_five_step_ahead\"\n",
    "cols_to_exclude = ['trade_time', 'is_buyer_maker', 'date',]\n",
    "# File to store the best global results\n",
    "BEST_GLOBAL_FILE = \"best_global.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataPrepare(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train test ratio is 0.01\n",
      "Train len for AVAX-USDT is 13536\n",
      "Test len for AVAX-USDT is 1340121\n",
      "Train len for DOGE-USDT is 32493\n",
      "Test len for DOGE-USDT is 3216827\n"
     ]
    }
   ],
   "source": [
    "data.train_test_split(train_test_ratio=0.01, cols_to_exclude=cols_to_exclude)\n",
    "X_train, y_train, X_test, y_test, = data.X_y_split(target_var=target_var, target_encode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load global best results from disk if they exist\n",
    "def load_best_global():\n",
    "    try:\n",
    "        with open(BEST_GLOBAL_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {\"study_name\": None, \"best_value\": float(\"inf\"), \"best_params\": None, \"features\": None}\n",
    "    \n",
    "# Save global best results to disk\n",
    "def save_best_global(best_global):\n",
    "    with open(BEST_GLOBAL_FILE, \"w\") as f:\n",
    "        json.dump(best_global, f, indent=4)\n",
    "\n",
    "# Initialize best global results\n",
    "best_global = load_best_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train, features):\n",
    "    # Store the features in trial user attributes\n",
    "    trial.set_user_attr(\"features\", features)\n",
    "\n",
    "    # Hyperparameter space\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 50)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 20)\n",
    "    min_weight_fraction_leaf = trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.5)\n",
    "    min_impurity_decrease = trial.suggest_float(\"min_impurity_decrease\", 0.0, 0.5)\n",
    "\n",
    "    # Define the RandomForestRegressor with trial parameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "        min_impurity_decrease=min_impurity_decrease,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Use K-Fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    mse_scores = -cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "\n",
    "    # Return the mean MSE score\n",
    "    return np.mean(mse_scores)\n",
    "\n",
    "# Function to plot feature importance\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Feature Importances\")\n",
    "    plt.bar(range(len(importances)), importances[indices], align=\"center\")\n",
    "    plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'study_name': 'study_2024-11-24_20-55-03',\n",
       " 'best_value': 102.65464869162608,\n",
       " 'best_params': {'n_estimators': 274,\n",
       "  'max_depth': 35,\n",
       "  'min_samples_split': 16,\n",
       "  'min_weight_fraction_leaf': 0.47962742547911763,\n",
       "  'min_impurity_decrease': 0.46498596544548115},\n",
       " 'features': ['price',\n",
       "  'quantity',\n",
       "  'quote',\n",
       "  'last_ask',\n",
       "  'last_bid',\n",
       "  'target',\n",
       "  'spread',\n",
       "  'cum_quote',\n",
       "  'minute_sin',\n",
       "  'minute_cos',\n",
       "  'hour_sin',\n",
       "  'hour_cos',\n",
       "  'day_sin',\n",
       "  'day_cos',\n",
       "  'week_sin',\n",
       "  'week_cos',\n",
       "  'month_sin',\n",
       "  'month_cos',\n",
       "  'year_sin',\n",
       "  'year_cos',\n",
       "  'target_lag_1',\n",
       "  'price_lag_1',\n",
       "  'target_lag_2',\n",
       "  'price_lag_2',\n",
       "  'target_lag_3',\n",
       "  'price_lag_3',\n",
       "  'target_lag_5',\n",
       "  'price_lag_5',\n",
       "  'target_lag_7',\n",
       "  'price_lag_7',\n",
       "  'symbol_mean']}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_with_dataset(X_train, y_train, study_name=None):\n",
    "    global best_global\n",
    "\n",
    "    features = list(X_train.columns)\n",
    "\n",
    "    if study_name:\n",
    "        pass\n",
    "    if features == best_global[\"features\"]:\n",
    "        study_name = best_global[\"study_name\"]\n",
    "    else:\n",
    "        study_name = datetime.now().strftime(\"study_%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "\n",
    "    # Create a new study\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=\"sqlite:///optuna_study.db\",\n",
    "        direction=\"minimize\",\n",
    "        load_if_exists=True\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, features), n_trials=1)\n",
    "\n",
    "    # Update the global best result if the current study has a better score\n",
    "    if study.best_value < best_global[\"best_value\"]:\n",
    "        best_global.update(\n",
    "            {\n",
    "                \"study_name\": study_name,\n",
    "                \"best_value\": study.best_value,\n",
    "                \"best_params\": study.best_params,\n",
    "                \"features\": features,\n",
    "            }\n",
    "        )\n",
    "        # Save the updated best global results to disk\n",
    "        save_best_global(best_global)\n",
    "\n",
    "    # Print the best result for this study\n",
    "    print(f\"Study: {study_name}\")\n",
    "    print(f\"Best Value: {study.best_value}\")\n",
    "    print(f\"Best Params: {study.best_params}\")\n",
    "\n",
    "    # Return the study for further analysis if needed\n",
    "    return study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 21:05:06,245] Using an existing study with name 'study_2024-11-24_20-55-03' instead of creating a new one.\n",
      "[I 2024-11-24 21:06:17,820] Trial 1 finished with value: 0.004790861329879529 and parameters: {'n_estimators': 375, 'max_depth': 35, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.05844255098555712, 'min_impurity_decrease': 0.2738548387993085}. Best is trial 1 with value: 0.004790861329879529.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study: study_2024-11-24_20-55-03\n",
      "Best Value: 0.004790861329879529\n",
      "Best Params: {'n_estimators': 375, 'max_depth': 35, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.05844255098555712, 'min_impurity_decrease': 0.2738548387993085}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<optuna.study.study.Study at 0x1e621424080>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimize_with_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 20:36:34,019] Using an existing study with name 'study_name' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study initialized successfully.\n",
      "Study name: study_name\n",
      "Number of trials: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0542f0075ea3497fbb1a3d59f42e7b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2024-11-24 20:36:34,252] Trial 8 finished with value: 2148.826437996637 and parameters: {'x': -46.36622087249118, 'y': -1}. Best is trial 2 with value: 0.004790859827390177.\n",
      "[I 2024-11-24 20:36:34,350] Trial 9 finished with value: 140.24159110970777 and parameters: {'x': 11.884510554066068, 'y': -1}. Best is trial 2 with value: 0.004790859827390177.\n",
      "Best hyperparameters: {'n_estimators': 304, 'max_depth': 14, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.14780216944703894, 'min_impurity_decrease': 0.4894995858813643}\n",
      "Best MSE: 0.004790859827390177\n"
     ]
    }
   ],
   "source": [
    "optuna.create_study(\n",
    "    study_name=\"study_name\",\n",
    "    storage=\"sqlite:///optuna_study.db\",  # Initialize SQLite storage\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "print(\"Study initialized successfully.\")\n",
    "study = optuna.load_study(\n",
    "    study_name=\"study_name\",\n",
    "    storage=\"sqlite:///optuna_study.db\"\n",
    ")\n",
    "print(f\"Study name: {study.study_name}\")\n",
    "print(f\"Number of trials: {len(study.trials)}\")\n",
    "\n",
    "study.optimize(objective, n_trials=2, show_progress_bar=True)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best MSE:\", study.best_value)\n",
    "\n",
    "# Visualize optimization progress\n",
    "#optuna.visualization.plot_optimization_history(study).show()\n",
    "#optuna.visualization.plot_parallel_coordinate(study).show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microstructure-price-prediction-p_py7spM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
