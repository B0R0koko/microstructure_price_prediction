{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(r'C:\\Users\\310\\Desktop\\Progects_Py\\data\\microstructure_price_prediction_data\\cross_section\\df_cross_section_V0.1_.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here we are going to use our precomputed features and some raw inputs. We are going to drop \"target\" (use target_one_step_ahead instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(pl.exclude(\"target\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len for AVAX-USDT is 275832\n",
      "Test len for AVAX-USDT is 2482491\n",
      "Train len for DOGE-USDT is 731709\n",
      "Test len for DOGE-USDT is 6585382\n"
     ]
    }
   ],
   "source": [
    "train_test_ratio = 0.1\n",
    "\n",
    "\n",
    "df_train = pl.DataFrame()\n",
    "df_test = pl.DataFrame()\n",
    "\n",
    "for currency_pair in df[\"symbol\"].unique():\n",
    "\n",
    "    curr_df = df.filter(pl.col('symbol') == currency_pair)\n",
    "    split_indx = int(len(curr_df) * train_test_ratio)\n",
    "    \n",
    "    train = curr_df[:split_indx]\n",
    "    test = curr_df[split_indx:]\n",
    "\n",
    "    print(f'Train len for {currency_pair} is {len(train)}')\n",
    "    print(f'Test len for {currency_pair} is {len(test)}')\n",
    "\n",
    "    df_train = df_train.vstack(train) if not df_train.is_empty() else train\n",
    "    df_test = df_test.vstack(test) if not df_test.is_empty() else test\n",
    "\n",
    "df_train_pd = df_train.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     trade_time     price  quantity  is_buyer_maker  \\\n",
      "0       2024-06-01 00:00:08.502  36.04000      6.43           False   \n",
      "1       2024-06-01 00:00:08.511  36.05000      8.40           False   \n",
      "2       2024-06-01 00:00:08.513  36.05000     24.72           False   \n",
      "3       2024-06-01 00:00:08.514  36.05000      1.90           False   \n",
      "4       2024-06-01 00:00:08.515  36.05000     32.55           False   \n",
      "...                         ...       ...       ...             ...   \n",
      "1007536 2024-06-08 17:53:42.426   0.14550   1000.00            True   \n",
      "1007537 2024-06-08 17:53:42.427   0.14550   6382.00            True   \n",
      "1007538 2024-06-08 17:53:42.898   0.14548   4000.00            True   \n",
      "1007539 2024-06-08 17:53:42.935   0.14548     53.00           False   \n",
      "1007540 2024-06-08 17:53:45.698   0.14546   2100.00            True   \n",
      "\n",
      "              date     symbol       quote  last_ask  last_bid   spread  ...  \\\n",
      "0       2024-06-01  AVAX-USDT   231.73720       NaN  36.04000      NaN  ...   \n",
      "1       2024-06-01  AVAX-USDT   302.82000       NaN  36.05000      NaN  ...   \n",
      "2       2024-06-01  AVAX-USDT   891.15600       NaN  36.05000      NaN  ...   \n",
      "3       2024-06-01  AVAX-USDT    68.49500       NaN  36.05000      NaN  ...   \n",
      "4       2024-06-01  AVAX-USDT  1173.42750       NaN  36.05000      NaN  ...   \n",
      "...            ...        ...         ...       ...       ...      ...  ...   \n",
      "1007536 2024-06-08  DOGE-USDT   145.50000   0.14550   0.14550  0.00000  ...   \n",
      "1007537 2024-06-08  DOGE-USDT   928.58100   0.14550   0.14550  0.00000  ...   \n",
      "1007538 2024-06-08  DOGE-USDT   581.92000   0.14548   0.14550  0.00002  ...   \n",
      "1007539 2024-06-08  DOGE-USDT     7.71044   0.14548   0.14548  0.00000  ...   \n",
      "1007540 2024-06-08  DOGE-USDT   305.46600   0.14546   0.14548  0.00002  ...   \n",
      "\n",
      "         price_lag_1  target_lag_2  price_lag_2  target_lag_3  price_lag_3  \\\n",
      "0                NaN           NaN          NaN           NaN          NaN   \n",
      "1           36.04000           NaN          NaN           NaN          NaN   \n",
      "2           36.05000           NaN     36.04000           NaN          NaN   \n",
      "3           36.05000           NaN     36.05000           NaN      36.0400   \n",
      "4           36.05000           NaN     36.05000           NaN      36.0500   \n",
      "...              ...           ...          ...           ...          ...   \n",
      "1007536      0.14550       0.14550      0.14550        0.1455       0.1455   \n",
      "1007537      0.14550       0.14550      0.14550        0.1455       0.1455   \n",
      "1007538      0.14550       0.14550      0.14550        0.1455       0.1455   \n",
      "1007539      0.14548       0.14550      0.14550        0.1455       0.1455   \n",
      "1007540      0.14548       0.14549      0.14548        0.1455       0.1455   \n",
      "\n",
      "         target_lag_5  price_lag_5  target_lag_7  price_lag_7  \\\n",
      "0                 NaN          NaN           NaN          NaN   \n",
      "1                 NaN          NaN           NaN          NaN   \n",
      "2                 NaN          NaN           NaN          NaN   \n",
      "3                 NaN          NaN           NaN          NaN   \n",
      "4                 NaN          NaN           NaN          NaN   \n",
      "...               ...          ...           ...          ...   \n",
      "1007536      0.145475       0.1455      0.145455      0.14545   \n",
      "1007537      0.145500       0.1455      0.145460      0.14547   \n",
      "1007538      0.145500       0.1455      0.145475      0.14550   \n",
      "1007539      0.145500       0.1455      0.145500      0.14550   \n",
      "1007540      0.145500       0.1455      0.145500      0.14550   \n",
      "\n",
      "         target_one_step_ahead  \n",
      "0                          NaN  \n",
      "1                          NaN  \n",
      "2                          NaN  \n",
      "3                          NaN  \n",
      "4                          NaN  \n",
      "...                        ...  \n",
      "1007536                0.14550  \n",
      "1007537                0.14549  \n",
      "1007538                0.14548  \n",
      "1007539                0.14547  \n",
      "1007540                0.14547  \n",
      "\n",
      "[1007541 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train_pd = df_train_pd.set_index(['symbol', 'trade_time'])\n",
    "\n",
    "#X = df_train.select(pl.exclude('target_one_step_ahead')).to_pandas()\n",
    "#y = df_train.select(pl.col(\"target_one_step_ahead\")).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trade_time\n",
       "2024-06-01 00:00:03.927    0.158985\n",
       "2024-06-01 00:00:06.777    0.158985\n",
       "2024-06-01 00:00:07.152    0.158985\n",
       "2024-06-01 00:00:07.156    0.158985\n",
       "2024-06-01 00:00:07.405    0.158990\n",
       "                             ...   \n",
       "2024-06-08 17:53:42.426    0.145500\n",
       "2024-06-08 17:53:42.427    0.145490\n",
       "2024-06-08 17:53:42.898    0.145480\n",
       "2024-06-08 17:53:42.935    0.145470\n",
       "2024-06-08 17:53:45.698    0.145470\n",
       "Name: target_one_step_ahead, Length: 1002177, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pd.groupby(\"trade_time\")[\"target_one_step_ahead\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = df_train.with_columns([\n",
    "#    pl.struct(['symbol', 'trade_time']).alias('multi_index')\n",
    "#])\n",
    "\n",
    "#le = LabelEncoder()\n",
    "#df_train['multi_index'] = le.fit_transform(df_train['multi_index'])\n",
    "\n",
    "#df_train = df_train.select(pl.exclude(\"trade_time\", \"date\", \"symbol\", \"is_buyer_maker\",))\n",
    "\n",
    "\n",
    "\n",
    "#X = df_train.select(pl.exclude('target_one_step_ahead')).to_pandas().dropna()\n",
    "#y = df_train.select(pl.col(\"target_one_step_ahead\")).to_pandas().dropna()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train_pd.drop(columns=[\"target_one_step_ahead\"])\n",
    "y = df_train_pd[\"target_one_step_ahead\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Random Forest:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 887, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.exceptions.DTypePromotionError: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 19\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize Random Forest with hyperparameters\u001b[39;00m\n\u001b[0;32m      4\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[0;32m      5\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# Default, adjust if needed\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     17\u001b[0m )\n\u001b[1;32m---> 19\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m rf\u001b[38;5;241m.\u001b[39mfit(X\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1000\u001b[39m), y\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m     22\u001b[0m progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 363, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\310\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\microstructure-price-prediction-p_py7spM-py3.12\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 887, in check_array\n    dtype_orig = np.result_type(*dtypes_orig)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.exceptions.DTypePromotionError: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.BoolDType'>, <class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)\n"
     ]
    }
   ],
   "source": [
    "progress = tqdm(total=1, desc=\"Training Random Forest\")\n",
    "\n",
    "# Initialize Random Forest with hyperparameters\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=100,  # Default, adjust if needed\n",
    "    criterion='squared_error',\n",
    "    max_depth=10,      # Maximum depth of random tree\n",
    "    min_samples_split=50,  # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=20, #Minimum number of samples required to be at a leaf node\n",
    "    min_weight_fraction_leaf=0.2, #Minimum weighted fraction of the sum of weights required at a leaf node\n",
    "    #max_features='auto', #Number of features considered when looking for the best split\n",
    "    max_leaf_nodes=100, #Maximum number of leaf nodes in a tree\n",
    "    min_impurity_decrease=0.01,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,         # Use all cores for faster training\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(rf, X.head(1000), y.head(1000), cv=5, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "rf.fit(X.head(1000), y.head(1000))\n",
    "progress.update(1)\n",
    "progress.close()\n",
    "\n",
    "# Results\n",
    "print(f\"Cross-Validation Scores: {cv_scores}\")\n",
    "print(f\"Mean CV RÂ²: {np.mean(cv_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microstructure-price-prediction-p_py7spM-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
